---
title: "Semana 3. Simulación del LiDAR en Carla y Detección por parches planos"
categories:
  - Weblog
tags:
  - Lidar
  - Carla
---

En la tercera semana he comenzado a investigar el funcionamiento y la simulación del **sensor LiDAR en CARLA**. EL simulador proporciona un conjunto de **blueprints de sensores** 
que permiten integrar fácilmente diferentes tipos de percepción para los vehículos virtuales sin necesidad de crear el hardware desde cero.

## Sensores disponibles en CARLA

El simulador ofrece múltiples sensores listos para usar, entre los que destacan:

- **Cámara RGB** (`sensor.camera.rgb`): simula una cámara normal.  
- **Cámara de profundidad** (`sensor.camera.depth`): genera mapas de profundidad.  
- **Cámara semántica** (`sensor.camera.semantic_segmentation`): asigna una clase de objeto a cada píxel.  
- **Cámara de flujo óptico** (`sensor.camera.optical_flow`): calcula el movimiento entre cuadros consecutivos.  
- **LiDAR** (`sensor.lidar.ray_cast`): simula un sensor LiDAR 3D clásico.  
- **GNSS** (`sensor.other.gnss`): proporciona coordenadas GPS (latitud, longitud, altitud).  
- **IMU** (`sensor.other.imu`): entrega aceleraciones y velocidades angulares.  
- **Radar** (`sensor.other.radar`): mide distancia y velocidad relativa.  
- **Velocímetro** (`sensor.speedometer`): informa de la velocidad del vehículo.

## Simulación del LiDAR en CARLA

El LiDAR en CARLA se basa en el principio de **Ray Casting**, que consiste en lanzar rayos desde la posición del sensor hacia el entorno y registrar los puntos de impacto.  
Este proceso se desarrolla en varias etapas:

1. **Configuración de parámetros**  
   Se definen propiedades como el número de canales, rango y frecuencia de rotación. Con estos valores se determina cuántos rayos se lanzan por cada *tick* de simulación.

2. **Generación de rayos**  
   Cada rayo se orienta según una **distribución angular**, simulando el barrido del sensor real.

3. **Ray Casting (detección de impactos)**  
   Mediante funciones del motor **Unreal Engine**, cada rayo detecta colisiones con el entorno.  
   Si se produce un impacto, se almacena la **coordenada 3D del punto de colisión**.

4. **Construcción de la nube de puntos**  
   Los puntos detectados se transforman al **marco de referencia del sensor**.  
   Además, se añade información complementaria como **intensidad del retorno** y **etiqueta semántica**.  
   Finalmente, los datos se empaquetan en una estructura binaria denominada **Lidar Measurement**.

5. **Transmisión al cliente Python**  
   La nube de puntos se envía al cliente mediante la **API de streaming de CARLA**, permitiendo su procesamiento en tiempo real.

## Realismo del modelo LiDAR

Aunque CARLA no simula la óptica real del sensor, reproduce de forma precisa los **parámetros geométricos** y **temporales** del LiDAR.  
En particular:
- Se simulan correctamente **distancias, ángulos y frecuencias de muestreo**.  
- Sin embargo, la **intensidad del retorno** es una versión simplificada que **no depende del material ni del color de las superficies**.  
- El **ruido** se introduce de manera artificial para aumentar la variabilidad y realismo de los datos.

## Conclusión

El estudio del **LiDAR en CARLA** me ha permitido comprender cómo se genera y transmite la **nube de puntos simulada**, así como las **limitaciones del modelo físico** respecto a sensores reales.  
Este conocimiento servirá como base para futuras tareas dónde se pueda mejorar su uso y hacerlo más eficiente.
